{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL Integrate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PIYJG6X_1oRf4cEcVxE4Dwa4OuQ7bWWg",
      "authorship_tag": "ABX9TyMubNm476CfOFT/gOcnc/BV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArpitaChatterjee/AmericanSignLanguage/blob/main/ASL_Integrate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1jLC9CqqoUk"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXP8z7BsrT3y",
        "outputId": "335f1e8e-b06a-4bff-c1f8-154da61bc9c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rescale = 1./255, \n",
        "                             shear_range = 0.2,\n",
        "                             validation_split = 0.1, \n",
        "                             zoom_range = 0.2,  \n",
        "                             horizontal_flip = True,\n",
        "                             samplewise_center = True, \n",
        "                             samplewise_std_normalization = True)\n",
        "\n",
        "training_set = datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/ASL/ASL-DATASETS/asl_alphabet_train', \n",
        "                                           target_size = (64, 64), \n",
        "                                           batch_size = 16,\n",
        "                                           class_mode = 'categorical',\n",
        "                                           subset = 'training')\n",
        "\n",
        "test_set = datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/ASL/ASL-DATASETS/asl_alphabet_train',\n",
        "                                       target_size = (64, 64), \n",
        "                                       batch_size = 16,\n",
        "                                       class_mode = 'categorical', \n",
        "                                       subset = 'validation')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 57319 images belonging to 29 classes.\n",
            "Found 6367 images belonging to 29 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqvWpQG8sKGa"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "# Initialising the CNN\n",
        "cnn = Sequential()\n",
        "\n",
        "#First Layer\n",
        "cnn.add(Conv2D(filters = 64, kernel_size = (4, 4), \n",
        "                      input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "cnn.add(Conv2D(filters = 64, kernel_size = (4, 4), strides = 2,  activation = 'relu'))\n",
        "\n",
        "cnn.add(Dropout(0.5))\n",
        "\n",
        "cnn.add(BatchNormalization(axis = 3, momentum = 0.8))\n",
        "\n",
        "#Second Layer\n",
        "cnn.add(Conv2D(filters = 128, kernel_size = (4, 4), activation = 'relu'))\n",
        "\n",
        "cnn.add(Conv2D(filters = 128, kernel_size = (4, 4), strides = 2,  activation = 'relu'))\n",
        "\n",
        "cnn.add(Dropout(0.5))\n",
        "\n",
        "cnn.add(BatchNormalization(axis = 3, momentum = 0.8))\n",
        "\n",
        "#Third Layer\n",
        "\n",
        "cnn.add(Conv2D(filters = 256, kernel_size = (4, 4), activation = 'relu'))\n",
        "\n",
        "cnn.add(Conv2D(filters = 256, kernel_size = (4, 4), strides = 2,  activation = 'relu'))\n",
        "\n",
        "cnn.add(Dropout(0.5))\n",
        "\n",
        "cnn.add(BatchNormalization(axis = 3, momentum = 0.8))\n",
        "\n",
        "# Flattening\n",
        "cnn.add(Flatten())\n",
        "\n",
        "cnn.add(Dropout(0.5))\n",
        "\n",
        "# Hidden Layer and Output Layer\n",
        "cnn.add(Dense(units = 512, activation = 'relu'))\n",
        "cnn.add(Dense(units = 29, activation = 'softmax'))\n",
        "\n",
        "#Compiling the CNN\n",
        "cnn.compile(optimizer= 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zcJcdiTsfRs",
        "outputId": "0c5b8d6a-e182-4f09-d763-a23ceb686d98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "r = cnn.fit_generator(training_set,                  \n",
        "                  epochs = 10,\n",
        "                  validation_data = test_set,\n",
        "                  steps_per_epoch = len(training_set), \n",
        "                  validation_steps = len(test_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-517fee002139>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/10\n",
            " 211/3583 [>.............................] - ETA: 6:22:35 - loss: 3.8114 - accuracy: 0.0847"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X2h8cmLtMif"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluate on test data\")\n",
        "results = cnn.evaluate(test_set, batch_size=16)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}